{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8258ee85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import mediapipe as mp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62aa6b2b",
   "metadata": {},
   "source": [
    "###### Chargement de modèle entrainé avec joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3a2cb1e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_model_loaded = joblib.load('asl_svm_model.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c623e861",
   "metadata": {},
   "source": [
    "###### Extraction et représentation des landmarks de la main sur l'image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "66c6340c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_landmarks(image, results, mpDraw):\n",
    "    # Extraction des dimensions de l'image\n",
    "    h, w, c = image.shape\n",
    "    # Initialisation du tableau pour stocker les coordonnées des landmarks\n",
    "    landmarks_array = []\n",
    "    \n",
    "    # Vérification de la présence de landmarks pour une seule main dans les résultats\n",
    "    if results.multi_hand_landmarks:\n",
    "        # Récupération des landmarks de la première main détectée\n",
    "        hand_landmarks = results.multi_hand_landmarks[0]\n",
    "            \n",
    "        # Extraction des coordonnées des landmarks\n",
    "        landmarks = hand_landmarks.landmark\n",
    "        landmarks_row = []\n",
    "            \n",
    "        # Boucle à travers chaque landmark\n",
    "        for landmark in landmarks:\n",
    "                \n",
    "            # Dessin d'un cercle pour représenter chaque landmark sur l'image\n",
    "            cx, cy = int(landmark.x * w), int(landmark.y * h)\n",
    "            \n",
    "             # Stockage des coordonnées des landmarks dans le tableau\n",
    "            landmarks_row.extend([cx, cy])\n",
    "            cv2.circle(image, (cx, cy), 15, (255, 0, 255), cv2.FILLED)\n",
    "                \n",
    "        # Stockage des coordonnées des landmarks de la main dans le tableau principal\n",
    "        landmarks_array.append(landmarks_row)\n",
    "        \n",
    "        # Dessin des connexions entre les landmarks de la main sur l'image\n",
    "        mpDraw.draw_landmarks(image, hand_landmarks, mpHands.HAND_CONNECTIONS)\n",
    "        \n",
    "        # Retour de l'image avec les landmarks dessinés et des coordonnées des landmarks\n",
    "        return image, np.array(landmarks_array).flatten()\n",
    "    else:\n",
    "        # Si aucun landmark n'est détecté ou si plusieurs mains sont détectées, retourne None\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87f2e9f0",
   "metadata": {},
   "source": [
    "###### Configuration de la capture vidéo de la webcam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "034f935a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Capture vidéo en direct à partir de la webcam (index 0)\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Taille désirée pour la webcam\n",
    "webcam_width, webcam_height = 400, 400\n",
    "\n",
    "# # Ajustement de la taille de la webcam\n",
    "cap.set(cv2.CAP_PROP_FRAME_WIDTH, webcam_width)\n",
    "cap.set(cv2.CAP_PROP_FRAME_HEIGHT, webcam_height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3d85ce60",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# Initialisation du temps écoulé\n",
    "start_time = time.time()\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()  # Lecture d'une image de la webcam\n",
    "    \n",
    "    if not ret:\n",
    "        break  # Sortir de la boucle si la lecture de la webcam échoue\n",
    "    \n",
    "    # Calculer le temps écoulé depuis la dernière capture de frame\n",
    "    elapsed_time = time.time() - start_time\n",
    "    \n",
    "    if elapsed_time >= 0.5:  # Capturer un frame toutes les 0.5 seconde\n",
    "        start_time = time.time()  # Réinitialiser le temps de départ\n",
    "        \n",
    "        results = hands.process(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB).astype(np.uint8))  # Traitement de l'image pour détecter les mains\n",
    "\n",
    "        if results.multi_hand_landmarks:  # Si des landmarks de main sont détectés\n",
    "            frame_marked, landmarks = extract_landmarks(frame, results, mpDraw)  # Extraction et dessin des landmarks de la main\n",
    "\n",
    "            landmarks_dataframe = pd.DataFrame([landmarks])  # Conversion des landmarks en DataFrame\n",
    "            class_ = svm_model_loaded.predict(landmarks_dataframe)  # Prédiction de la classe du geste de la main\n",
    "\n",
    "            # Affichage de la classe prédite sur l'image\n",
    "            cv2.putText(frame_marked, class_[0], (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 255), 2)\n",
    "            cv2.imshow('Classification en temps réel', frame_marked)  # Affichage de l'image avec les landmarks de la main et la classe prédite\n",
    "\n",
    "        else:\n",
    "            cv2.imshow('Classification en temps réel', frame)  # Affichage de l'image de la webcam si aucun landmark de main n'est détecté\n",
    "    \n",
    "    # Quitter la boucle si la touche 'q' est enfoncée\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Libération des ressources\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7e30a62",
   "metadata": {},
   "source": [
    "###### Classification en temps réel des gestes de la main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "68cd3071",
   "metadata": {},
   "outputs": [],
   "source": [
    "mpHands = mp.solutions.hands  # Importation du modèle de détection des mains\n",
    "hands = mpHands.Hands()  # Initialisation du détecteur de mains\n",
    "mpDraw = mp.solutions.drawing_utils  # Utilitaire pour dessiner les landmarks des mains\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()  # Lecture d'une image de la webcam\n",
    "    \n",
    "    if not ret:\n",
    "        break  # Sortir de la boucle si la lecture de la webcam échoue\n",
    "        \n",
    "    results = hands.process(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB).astype(np.uint8))  # Traitement de l'image pour détecter les mains\n",
    "\n",
    "    if results.multi_hand_landmarks:  # Si des landmarks de main sont détectés\n",
    "        frame_marked, landmarks = extract_landmarks(frame, results, mpDraw)  # Extraction et dessin des landmarks de la main\n",
    "        \n",
    "#         header =[f'ld_1_{i}' for i in range(1, 64)] + ['o_h'] + [f'ld_2_{i}' for i in range(1, 64)]\n",
    "        landmarks_dataframe = pd.DataFrame([landmarks])  # Conversion des landmarks en DataFrame\n",
    "        class_ = svm_model_loaded.predict(landmarks_dataframe)  # Prédiction de la classe du geste de la main\n",
    "        \n",
    "        # Affichage de la classe prédite sur l'image\n",
    "        cv2.putText(frame_marked, class_[0], (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 255), 2)\n",
    "        cv2.imshow('Classification en temps réel', frame_marked)  # Affichage de l'image avec les landmarks de la main et la classe prédite\n",
    "    \n",
    "    else:\n",
    "        cv2.imshow('Classification en temps réel', frame)  # Affichage de l'image de la webcam si aucun landmark de main n'est détecté\n",
    "    \n",
    "    # Quitter la boucle si la touche 'q' est enfoncée\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Libération des ressources\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "79dc30c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libérer la capture vidéo et fermer les fenêtres OpenCV\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
